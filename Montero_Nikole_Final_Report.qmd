---
title: "Final Report"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Nikole Montero Cervantes"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon=false}

## Github Repo Link

[https://github.com/stat301-2-2024-winter/final-project-2-Nikole26.git](https://github.com/stat301-2-2024-winter/final-project-2-Nikole26.git)

:::

```{r}
#| label: loading-packages-and-data
#| echo: false
library(tidyverse)
library(here)
```

## Introduction

The project objective is to develop a predictive model to determine the likelihood of small businesses or start-ups having their loan applications approved by the U.S. Small Business Administration (SBA). This predictive model focuses on classifying loan applications into two categories: "Approved" and "Rejected," utilizing the dependent variable loan status, which indicates if the loan is either "Charged Off" or "Paid in Full".

The motivation behind this project stems from my deep curiosity in understanding the dynamics between financial institutions and emerging enterprises, particularly the challenges startups face in securing loans. As an economics undergraduate interested in applying data science skills and knowledge to real-world business scenarios, this aspect of investigating the relationship between banks and startups caught my attention. By delving into these interactions, this project provides a meaningful way for me to apply my data science expertise in economics.

Predicting loan status is a vital aspect of risk assessment for financial institutions like the SBA. Accurately identifying loans at risk of default can lead to proactive risk management and mitigation strategies. Therefore, developing a robust predictive model can aid in streamlining loan approval processes, optimizing resource allocation, and ultimately reducing the likelihood of loan defaults.

Finally, the dataset used in this project was obtained from the U.S. Small Business Administration (SBA), publicly available on Kaggle, a platform dedicated to data science.

## Data Overview

## Methods

The following aspects where ocnsidering in the methodoly to apprac this project. 

### Type of prediction problem

This project focus on a classification problem where the goal is to classify loan applications into two categories: "Approved" or "Rejected" based on the loan status variable which indicates whether the loan is "Charged Off" (CHGOFF) or "Paid in Full" (PIF).

### Data Splitting

The data is initially split into training and testing sets using a 75/25 ratio. Stratified splitting is employed to ensure proportional representation of the target variable, which is the loan status, in both the training and testing datasets.

### Models 

##### 1. Naive Bayes:
It is chosen as one of the models due to its simplicity and efficiency, making it suitable for initial exploration of the data. 

##### 2. Binary Logistic Regression:
This model serves as a baseline model for comparison, given its simplicity and interpretability. By estimating the probability of loan approval based on input features, logistic regression can provide valuable insights into the relative importance of predictors and their impact on the loan approval decision.

##### 3. Elastic Net:
This regularized regression method that combines the penalties of both L1 (Lasso) and L2 (Ridge) regularization is useful to deal with high-dimensional data and multicollinearity.

Parameters to be tuned:
- Penalty: The penalty parameter controls the balance between L1 and L2 regularization. It will be tuned over a range of values.

##### 4. K-Nearest Neighbors (KNN):
KNN is included to capture potential non-linear relationships between features and loan approval status. In scenarios where decision boundaries are complex, KNN can provide a flexible and intuitive approach to classification tasks.

Parameters to be tuned:
- Number of neighbors (k): Determines the number of nearest neighbors to consider when making predictions. It will be tuned over a range of values.

##### 5. Boost Trees:
It is an ensemble learning model that combines multiple weak learners (typically decision trees) to create a strong predictive model. It iteratively builds trees, focusing on the mistakes of the previous iterations.

Parameters to be tuned over different values:
- Number of trees: The number of trees to include in the boosting process.
- Learning rate: Controls the contribution of each tree to the final model. It will be tuned over a range of values.

##### 6. Random Forest:
It is another ensemble learning method that constructs a multitude of decision trees at training time and outputs the class that is the mode of the classes of the individual trees.

Parameters to be tuned:
- Number of variables randomly sampled as candidates at each split (mtry).
- Minimum node size (min_n): The minimum number of data points allowed in a terminal node. It will be tuned over a range of values.

### Recipes

For this project there are two main recipes are considered Recipe 1, consider the baseline recipe, and a more complex one call Recipe 2. The baseline recipe involves steps such as removing irrelevant predictors, handling unknown levels, and one-hot encoding categorical variables. While Recipe 2 includes additional preprocessing steps such as handling correlated predictors and normalization of numeric predictors. Both recipes will be used in the models' fittings in order to know which one performs better. 

For the naive Bayes model, two separate recipes are used due to the inability to use a processioning step to one-hot encoding categorical variables. The baseline recipe for this model is simpler, while the enhanced recipe includes additional preprocessing steps such as recoding factors and normalization.

### Metric for Model Comparison

The metric used for model comparison and selection accuracy, as it provides a straightforward measure of each model's overall performance in classifying loan applications correctly. 

### Resampling Technique

Cross-validation is employed for model evaluation using 10 folds with 5 repeats. This technique helps in estimating the performance of the model on unseen data and reduces the risk of overfitting.

## Model Building & Selection

The models analysis and selection will be based on the accuracy of their performances.

```{r}
#| label: fig-results-recipe-1
#| fig-cap: Best Estimated Accuracy per model using Recipe 1
load(here("results/model_results_1.rda"))
model_results_1
```

In @fig-results-recipe-1 it is seen that the model with worst performance is Naive Bayes with a mean 0.610 based on the accuracy as metric. While the best model performing is Random Forest with a mean of 0.995. 

```{r}
#| label: fig-results-recipe-2
#| fig-cap: Best Estimated Accuracy per model using Recipe 1
load(here("results/model_results_2.rda"))
model_results_2
```

In @fig-results-recipe-2 it is seen that the model with worst performance is Naive Bayes with a mean 0.612 based on the accuracy as metric. While the best model performing is Random Forest with a mean of 0.994. 

### Best parameters for each model

The best performance of each model between the two recipes will be selected, and from them the best parameters will be determined for each.

####  Elastic Net
The penalty parameter was set to a very small value of 0.0000000001, indicating that the model heavily penalizes the coefficients of the predictors. While the mixture parameter is set to 1, indicating that the model is a pure Elastic Net, with equal mixing between L1 and L2 penalties.

Thus, considering that the penalty is already at a very small value, further exploration might not be necessary. Besides, by adjusting the penalty slightly to see if it improves model performance could  sacrifice too much interpretability.

####  K-Nearest Neighbors

####  Boosted Trees

####  Random Forest

### Recipes impact on methods' performances

Both recipes show consistent performance across different model types, with small standard errors for each metric. This suggests that the common preprocessing steps (such as removing certain columns and handling unknowns) benefit the stability of the model performance.

Indeed, Recipe 2 includes additional preprocessing steps compared to Recipe 1, such as removing highly correlated predictors and normalizing numeric predictors. However, these additional steps do not seem to significantly improve the overall model performance based on the accuracy metric. As shown in @fig-results-recipe-1 and @fig-results-recipe-2, the mean accuracy values for each model type in Recipe 2 are quite similar to those in Recipe 1. This suggests that the added complexity in preprocessing may not always translate into better predictive performance, at least based on the evaluation metric of accuracy.

Across both recipes, certain model types consistently perform better than others. Specifically, the Boost Tree and Random Forest models tend to have higher accuracy compared to Naive Bayes and KNN models. This is not surprising since the ensemble-based models (Boost Tree and Random Forest) are more effective in capturing the complex relationships in the data compared to simpler models like Naive Bayes and KNN.


## Final Model Analysis

## Conclusion

While Recipe 2 includes additional preprocessing steps, it does not lead to a substantial improvement in model performance compared to Recipe 1. The choice of model type appears to have a larger impact on performance, with ensemble-based models generally outperforming simpler models.
