---
title: "Final Report"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Nikole Montero Cervantes"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon=false}

## Github Repo Link

[https://github.com/stat301-2-2024-winter/final-project-2-Nikole26.git](https://github.com/stat301-2-2024-winter/final-project-2-Nikole26.git)

:::

## Introduction

The project objective is to develop a predictive model to determine the likelihood of small businesses or start-ups having their loan applications approved by the U.S. Small Business Administration (SBA). This predictive model focuses on classifying loan applications into two categories: "Approved" and "Rejected," utilizing the dependent variable loan status, which indicates if the loan is either "Charged Off" or "Paid in Full".

The motivation behind this project stems from my deep curiosity in understanding the dynamics between financial institutions and emerging enterprises, particularly the challenges startups face in securing loans. As an economics undergraduate interested in applying data science skills and knowledge to real-world business scenarios, this aspect of investigating the relationship between banks and startups caught my attention. By delving into these interactions, this project provides a meaningful way for me to apply my data science expertise in economics.

Predicting loan status is a vital aspect of risk assessment for financial institutions like the SBA. Accurately identifying loans at risk of default can lead to proactive risk management and mitigation strategies. Therefore, developing a robust predictive model can aid in streamlining loan approval processes, optimizing resource allocation, and ultimately reducing the likelihood of loan defaults.

Finally, the dataset used in this project was obtained from the U.S. Small Business Administration (SBA), publicly available on Kaggle, a platform dedicated to data science.

## Data Overview

## Methods


### Type of prediction problem

This project focus on a classification problem where the goal is to classify loan applications into two categories: "Approved" or "Rejected" based on the loan status variable which indicates whether the loan is "Charged Off" (CHGOFF) or "Paid in Full" (PIF).

### Data Splitting

The data is initially split into training and testing sets using a 75/25 ratio. Stratified splitting is employed to ensure proportional representation of the target variable, which is the loan status, in both the training and testing datasets.

### Models 

1. Naive Bayes:
It is chosen as one of the models due to its simplicity and efficiency, making it suitable for initial exploration of the data. 

2. Binary Logistic Regression:
This model serves as a baseline model for comparison, given its simplicity and interpretability. By estimating the probability of loan approval based on input features, logistic regression can provide valuable insights into the relative importance of predictors and their impact on the loan approval decision.

3. Elastic Net:
This regularized regression method that combines the penalties of both L1 (Lasso) and L2 (Ridge) regularization is useful to deal with high-dimensional data and multicollinearity.

Parameters to be tuned:
- Penalty: The penalty parameter controls the balance between L1 and L2 regularization. It will be tuned over a range of values.

4. K-Nearest Neighbors (KNN):
KNN is included to capture potential non-linear relationships between features and loan approval status. In scenarios where decision boundaries are complex, KNN can provide a flexible and intuitive approach to classification tasks.

Parameters to be tuned:
- Number of neighbors (k): Determines the number of nearest neighbors to consider when making predictions. It will be tuned over a range of values.

5. Boosted Trees:Boosted Trees:
It is an ensemble learning model that combines multiple weak learners (typically decision trees) to create a strong predictive model. It iteratively builds trees, focusing on the mistakes of the previous iterations.

Parameters to be tuned over different values:
- Number of trees: The number of trees to include in the boosting process.
- Learning rate: Controls the contribution of each tree to the final model. It will be tuned over a range of values.

6. Random Forest:
It is another ensemble learning method that constructs a multitude of decision trees at training time and outputs the class that is the mode of the classes of the individual trees.

Parameters to be tuned:
- Number of variables randomly sampled as candidates at each split (mtry).
- Minimum node size (min_n): The minimum number of data points allowed in a terminal node. It will be tuned over a range of values.

### Recipes




## Model Building & Selection


## Final Model Analysis

## Conclusion

