---
title: "Executive Summary: Exploring Small Business Loan Approval Likelihood"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Nikole Montero Cervantes"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon=false}

## Github Repo Link

[https://github.com/stat301-2-2024-winter/final-project-2-Nikole26.git](https://github.com/stat301-2-2024-winter/final-project-2-Nikole26.git)

:::

```{r}
#| label: loading-packages-and-data
#| echo: false
library(tidyverse)
library(here)
library(gt)
library(gtExtras)
```

# Introduction

The project objective is to develop a predictive model to determine the likelihood of small businesses or start-ups having their loan applications approved by the U.S. Small Business Administration (SBA). This predictive model focuses on classifying loan applications into two categories: 'Approved' and 'Rejected,' utilizing the dependent variable loan status, which indicates if the loan is either 'Charged Off' or 'Paid in Full'. The dataset was sourced from Kaggle, and this report presents key insights, findings, and future research recommendations.

# Main Insights and Findings

## Type of prediction problem

This project focus on a classification problem since the project aim to predict whether the loan is Charged Off or Paid in Full.

## Models Assesment

The assessment of various models was conducted based on their accuracy performance using the baseline recipe (Recipe 1) and a more complex recipe (Recipe 2) methodology. The evaluation comprised 50 iterations for each model to ensure robustness and reliability of results, and the accuracy results per method and recipe can be seen in the following tables:

```{r}
#| label: fig-results-recipe-1
#| fig-cap: Best Estimated Accuracy per model using baseline recipe (Recipe 1)
load(here("results/model_results_1.rda"))
model_results_1
```

```{r}
#| label: fig-results-recipe-2
#| fig-cap: Best Estimated Accuracy per model using a more complex recipe (Recipe 2)
load(here("results/model_results_2.rda"))
model_results_2
```

### Key findings per model

#### 1. Naive Bayes:

In both @fig-results-recipe-1 and @fig-results-recipe-2, Naive Bayes consistently exhibited the lowest performance with mean accuracies of 0.610 and 0.612, respectively.
KNN (K-nearest neighbors):

KNN demonstrated commendable performance across both assessments, maintaining mean accuracies above 0.90 in both @fig-results-recipe-1 and @fig-results-recipe-2.

#### 2. Binary Logistic Regression:

This model consistently achieved accuracies around 0.988, demonstrating reliability in classification tasks.

#### 3. Elastic Net:

Elastic Net showcased high accuracy levels, with mean scores close to 0.988 in both assessments, indicating stable performance.

#### 4. Boost Tree:

This model yielded mean accuracies exceeding 0.993 in @fig-results-recipe-1 and approximately 0.994 in @fig-results-recipe-2, highlighting its robustness.

#### 5. Random Forest:

Random Forest emerged as the top-performing model in both evaluations, with mean accuracies reaching 0.995 and 0.994 in @fig-results-recipe-1 and @fig-results-recipe-2, respectively.

### Overall Assessment

The comparison of models underscores the superiority of Random Forest in delivering consistently high accuracy across iterations. Its robust performance makes it a strong candidate for deployment in real-world applications. Conversely, Naive Bayes consistently trailed behind, suggesting limitations in its predictive capabilities compared to other models evaluated.

## Best Model Assessment

The assessment of the Random Forest model's performance involved comprehensive analysis utilizing various metrics including the confusion matrix, accuracy, and the receiver operating characteristic (ROC) curve.

### Confusion Matrix

```{r}
#| label: fig-table-confusion-matrix
#| fig-cap: Confusion Matrix
 tibble(
  Prediction = c("CHGOFF", "PIF"), 
  CHGOFF = c(3742, 30),
  PIF = c(8, 3720)
) |>
  gt() |>
  tab_spanner(
    label = "Truth",
    columns = c(CHGOFF, PIF)
  ) |>
  gt_add_divider(columns = "Prediction")
```

Interpreting those values:

* True Positives (TP): 3,742 instances correctly predicted as Charged Off.

* False Negatives (FN): 30 instances incorrectly predicted as Paid In Full when they were actually Charged Off.

* False Positives (FP): 8 instances incorrectly predicted as Charged Off when they were actually Paid In Full.

* True Negatives (TN): 3,720 instances correctly predicted as Paid In Full.

### Accuracy

The accuracy of the Random Forest model is 0.9949333, indicating its exceptional performance in correctly predicting outcomes for approximately 99.49% of instances in the testing data.

```{r}
#| label: fig-best-model-accuracy
#| fig-cap: Best Model Accuracy
load(here("results/acc_rf.rda"))
acc_rf
```

### Receiver Operating Characteristic (ROC) Curve

```{r}
#| label: fig-table-roc
#| fig-cap: ROC (Receiver Operating Characteristic Curve) 
load(here("results/roc_curve.rda"))
roc_curve
```

Main takeaways:

* The area under the ROC curve (AUC) is close to 1, indicating excellent discriminatory power.

* The model effectively balances sensitivity and specificity, making it highly reliable in classifying loan statuses as Charged Off or Paid in Full.

# Opportunity for future research

* Explore additional features and alternative modeling techniques to improve predictive performance.

* Investigate the generalization of the best model, Random Forest, across different geographical regions or loan types to broaden its applicability.

* Continue research and strategies in loan approval prediction modeling to refine existing methodologies and address evolving challenges and trends.

